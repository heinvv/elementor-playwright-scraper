name: Scrape

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to scrape'
        required: true
        type: string
      selectors:
        description: 'Comma-separated CSS selectors'
        required: true
        type: string
      timeout:
        description: 'Page load timeout in seconds'
        required: false
        default: '60'
        type: string
      elementor_base_url:
        description: 'Elementor converter base URL (optional; or set ELEMENTOR_BASE_URL secret)'
        required: false
        default: ''
        type: string

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Cache build
        uses: actions/cache@v4
        id: build-cache
        with:
          path: |
            dist
            node_modules/.cache
          key: build-${{ runner.os }}-${{ hashFiles('src/**/*.ts', 'package-lock.json') }}
          restore-keys: |
            build-${{ runner.os }}-

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('package-lock.json') }}

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: |
          if [ "${{ steps.playwright-cache.outputs.cache-hit }}" != "true" ]; then
            npx playwright install --with-deps chromium
          else
            npx playwright install chromium
          fi

      - name: Build
        run: npm run build

      - name: Run scraper
        id: scrape
        env:
          ELEMENTOR_BASE_URL: ${{ inputs.elementor_base_url || secrets.ELEMENTOR_BASE_URL }}
        run: |
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H-%M-%S-%3NZ")
          OUTPUT="results/scrape-${TIMESTAMP}.json"
          mkdir -p results
          TIMEOUT_MS=$((${{ inputs.timeout }} * 1000))
          npm run scrape:prod -- \
            --url "${{ inputs.url }}" \
            --selectors "${{ inputs.selectors }}" \
            --timeout "${TIMEOUT_MS}" \
            --output "${OUTPUT}"
          echo "output_file=${OUTPUT}" >> $GITHUB_OUTPUT

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results
          path: results/*.json
